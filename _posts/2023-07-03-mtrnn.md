# Multiple-Timescales Recurrent Neural Networks (MTRNN)

The MTRNN is a network architecture capable of learning long time dependencies more effectively than an Elman network.
This architecture is described in [Yamashita and Tani 2010](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000220#s4), 
__Emergence of Functional Hierarchy in a Multiple Timescale Neural Network Model: A Humanoid Robot Experiment__.

...

Tracing circles, triangles, and figure eights was not particularly challenging, but the circles swithching location after a few
revolutions were trickier.

The first trace of this kind that I trained to learn with the MTRNN consisted of 5 circular revolutions on the left, followed by
5 revolutions on the right, then back to the left, and so on. I used layer sizes of 10, 40, 8 for L0, H0, and H1, respectively.
The time constant for H0 was 3, and the one for H1 was 40.

Initially the network was only learning ...


This prompted me to increase the number of epochs. After 10000 epochs the error reached a very small value (~8e-05), and the results
can be seen below:


